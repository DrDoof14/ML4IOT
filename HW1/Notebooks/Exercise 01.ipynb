{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: This file doesn't contain argument parsers, argument parsers are availabe in the .py files</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Raw data has been collected using the sensor and Raspberry pi <br>\n",
    "After that we have to follow two Steps. <br>\n",
    "First we have to turn our raw data into a .csv file. <br>\n",
    "And after that in the second part we have use that .csv file in order to create the dataset using TFRecord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to convert the txt file containing the raw file into a csv file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "file=pd.read_csv(r'rt.txt', header=None)\n",
    "file.columns = ['date', 'time', 'temperature','humidity']\n",
    "file.to_csv(r'rt.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The First Step in done!<br>\n",
    "Now we have to use the .csv file to creat the dataset<br>\n",
    "but before that, we need to change the date and time column into a POSIX timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1637176627.0, 1637176632.0, 1637176637.0, 1637176643.0]\n"
     ]
    }
   ],
   "source": [
    "cols=['date','time']\n",
    "conv = pd.read_csv(\"rt.csv\",usecols=cols).values#reading the csv file\n",
    "#code to convert the date and time to POSIX fornmat\n",
    "timestamp=[]\n",
    "for i in conv:\n",
    "    temp=i[0]+' '+i[1]\n",
    "    element = datetime.datetime.strptime(temp,\"%d/%m/%Y %H:%M:%S\")\n",
    "    tuple = element.timetuple()\n",
    "    timestamp.append(time.mktime(tuple))\n",
    "print(timestamp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to make a new CSV file in order to use as an input to our script<br>\n",
    "The new CSV file will have 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv= pd.read_csv(\"rt.csv\")\n",
    "new_csv=new_csv.drop(['date','time'],axis=1)\n",
    "new_csv.insert(0,\"datetime\",timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  temperature  humidity\n",
       "0  1.637177e+09           22        52\n",
       "1  1.637177e+09           22        52\n",
       "2  1.637177e+09           22        52\n",
       "3  1.637177e+09           22        52"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'d' has type <class 'str'>, but expected one of: numbers.Real",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16084/3447593938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\u001b[0m in \u001b[0;36mextend\u001b[1;34m(self, elem_seq)\u001b[0m\n\u001b[0;32m    280\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_type_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem_seq_iter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    280\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_type_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem_seq_iter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\u001b[0m in \u001b[0;36mCheckValue\u001b[1;34m(self, proposed_value)\u001b[0m\n\u001b[0;32m    278\u001b[0m       message = ('%.1024r has type %s, but expected one of: numbers.Real' %\n\u001b[0;32m    279\u001b[0m                  (proposed_value, type(proposed_value)))\n\u001b[1;32m--> 280\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[0mconverted_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproposed_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;31m# This inf rounding matches the C++ proto SafeDoubleToFloat logic.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'd' has type <class 'str'>, but expected one of: numbers.Real"
     ]
    }
   ],
   "source": [
    "# # #we delete the name of the columns\n",
    "\n",
    "# with tf.io.TFRecordWriter(args.output) as writer:\n",
    "#     for row in new_csv:\n",
    "#         features, label = row[:-1], row[-1]\n",
    "#         example = tf.train.Example()\n",
    "#         example.features.feature[\"features\"].float_list.value.extend(features)\n",
    "#         example.features.feature[\"label\"].float_list.value.append(label)\n",
    "#         writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the code below to show the size of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to see the size of created TFRecord\n",
    "# import os\n",
    "# print(os.path.getsize(args.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to create the normalization function and then after that apply it to our input data<br>\n",
    "and the run the code again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the normalization function\n",
    "def norm(t,t_min,t_max):\n",
    "    return (t-t_min)/(t_max-t_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>minimum</b> and <b>maximum</b> values for <b>temperature</b> is equal to 0 and 50 (according to the technical data sheet) <br>\n",
    "The values for <b>humidity vary based on the temperature</b>:\n",
    "\n",
    "temperature = 0  ==> humidity =  30% - 90% <br>\n",
    "temperature = 25 ==> humidity =  20% - 90% <br>\n",
    "temperature = 50 ==> humidity =  30% - 80% <br>\n",
    "</b>\n",
    "</b>\n",
    "Now we have to apply the function to our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see the data we are working with, so we plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_csv['temperature'].plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_csv['humidity'].plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data gathered is exactly the same during different periods of time <br>\n",
    "Technically there is no need to normalize the data but since it is needed for the exercise, it'll be performed anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = new_csv.loc[:,'temperature']\n",
    "humidity = new_csv.loc[:,'humidity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22\n",
       "1    22\n",
       "2    22\n",
       "3    22\n",
       "Name: temperature, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52\n",
       "1    52\n",
       "2    52\n",
       "3    52\n",
       "Name: humidity, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_temperature=[]\n",
    "for i in temperature:\n",
    "    norm_temperature.append(norm(i,0,50))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_humidity=[]\n",
    "for i in humidity:\n",
    "    norm_humidity.append(norm(i,20,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44, 0.44, 0.44, 0.44]\n"
     ]
    }
   ],
   "source": [
    "print(norm_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45714285714285713, 0.45714285714285713, 0.45714285714285713, 0.45714285714285713]\n"
     ]
    }
   ],
   "source": [
    "print(norm_humidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is normalized and we have to create a dataframe again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data={'datetime':new_csv.loc[:,'datetime'],'temperature':norm_temperature,'humidity':norm_humidity}\n",
    "norm_csv=pd.DataFrame(data=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  temperature  humidity\n",
       "0  1.637177e+09         0.44  0.457143\n",
       "1  1.637177e+09         0.44  0.457143\n",
       "2  1.637177e+09         0.44  0.457143\n",
       "3  1.637177e+09         0.44  0.457143"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_csv #normalized one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is ready to be given to our script again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.637177e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  temperature  humidity\n",
       "0  1.637177e+09           22        52\n",
       "1  1.637177e+09           22        52\n",
       "2  1.637177e+09           22        52\n",
       "3  1.637177e+09           22        52"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_csv #without normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to create the new TFRecord dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(args.output) as writer:\n",
    "    for row in new_csv:\n",
    "        features, label = row[:-1], row[-1]\n",
    "        example = tf.train.Example()\n",
    "        example.features.feature[\"features\"].float_list.value.extend(features)\n",
    "        example.features.feature[\"label\"].float_list.value.append(label)\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to see the size of created TFRecord\n",
    "print(os.path.getsize(args.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, We can easily compare the size of the created TFRecord datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we have to first import the audio file we want to use for our script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen\n",
    "Popen('sudo sh -c \"echo performance >'\n",
    " '/sys/devices/system/cpu/cpufreq/policy0/scaling_governor\"', \n",
    " shell=True).wait()\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import linalg as LNG\n",
    "\n",
    "dir_list=os.listdir('./yes_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to read all the audio files and add them to a list\n",
    "audio=[]\n",
    "for i in dir_list:\n",
    "    audio.append(tf.io.read_file('./yes_no/'+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we only work with one audio file to <b>test the procedure</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio=tf.io.read_file('./yes_no/no_0ab3b47d_nohash_0.wav')\n",
    "tf_audio, rate=tf.audio.decode_wav(test_audio)\n",
    "tf_audio = tf.squeeze(tf_audio, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.0270s\n",
      "Spectrogram shape: (1999, 9)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "frame_length=16\n",
    "frame_step=8\n",
    "start = time.time()\n",
    "stft = tf.signal.stft(tf_audio, frame_length, frame_step,\n",
    "        fft_length=frame_length)\n",
    "end = time.time()\n",
    "print('Execution Time: {:.4f}s'.format(end-start))\n",
    "spectrogram = tf.abs(stft)\n",
    "print('Spectrogram shape:', spectrogram.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the spectogram of the audio file using STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.072s\n",
      "MFCCs shape: (1999, 10)\n"
     ]
    }
   ],
   "source": [
    "num_spectrogram_bins = spectrogram.shape[-1]\n",
    "num_mel_bins = 40\n",
    "sampling_rate = 16000\n",
    "lower_freq=20\n",
    "upper_freq=4000\n",
    "coefficients=10\n",
    "start = time.time()\n",
    "linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "        num_mel_bins, num_spectrogram_bins, sampling_rate, lower_freq, upper_freq)\n",
    "mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
    "log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "mfccs = mfccs[..., :coefficients]\n",
    "end = time.time()\n",
    "print('Execution Time: {:.3f}s'.format(end-start))\n",
    "print('MFCCs shape:', mfccs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the testing is done and we can work on the whole dataset in order to compute MFCC<sub>slow</sub> <br>\n",
    "We use a for loop for that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average execution time of each iteration:  0.025940912127494813\n"
     ]
    }
   ],
   "source": [
    "# now we get the rate of our audio\n",
    "#these info are extracted from the homework pdf file\n",
    "total_time=0 #to sum up the time of execution in each iteration\n",
    "frame_length=16\n",
    "frame_step=8\n",
    "num_mel_bins = 40\n",
    "sampling_rate = 16000\n",
    "lower_freq=20\n",
    "upper_freq=4000\n",
    "coefficients=10\n",
    "total_mfcc=0\n",
    "for i in audio:\n",
    "    tf_audio, rate = tf.audio.decode_wav(i)\n",
    "    tf_audio = tf.squeeze(tf_audio, 1)\n",
    "    start = time.time()\n",
    "    stft = tf.signal.stft(tf_audio, frame_length, frame_step,\n",
    "    fft_length=frame_length)\n",
    "    spectrogram = tf.abs(stft)\n",
    "    num_spectrogram_bins = spectrogram.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "        num_mel_bins, num_spectrogram_bins, sampling_rate, lower_freq, upper_freq)\n",
    "    mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "    mfccs = mfccs[..., :coefficients]\n",
    "    end = time.time()\n",
    "    total_mfcc=total_mfcc+mfccs\n",
    "    total_time=total_time+end-start\n",
    "    \n",
    "avg_time=total_time/len(audio)\n",
    "avg_mfcc_slow=total_mfcc/len(audio)\n",
    "print('average execution time of each iteration: ',avg_time)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average execution time of each iteration on Raspberry pi was equal to 0.1743576855659485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to computer MFCC<sub>Fast</sub> <br>\n",
    "The shape of it must be similiar to the slow one so the inputs are the same.<br>\n",
    "Now we have to work with different variables and other elements in our code in order to make it more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC<sub>Fast</sub> is as below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the script below in order to test different possible values for number of bins and fine the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subprocess import Popen\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# Popen('sudo sh -c \"echo performance >'\n",
    "#       '/sys/devices/system/cpu/cpufreq/policy0/scaling_governor\"',\n",
    "#       shell=True).wait()\n",
    "\n",
    "# dir_list = os.listdir('./yes_no')\n",
    "\n",
    "# audio = []\n",
    "# for i in dir_list:\n",
    "#     audio.append(tf.io.read_file('./yes_no/' + i))\n",
    "# frame_length = 16\n",
    "# frame_step = 8\n",
    "# num_mel_bins = 5\n",
    "# sampling_rate = 16000\n",
    "# lower_freq = 20\n",
    "# upper_freq = 4000\n",
    "# coefficients = 10\n",
    "# tstFile = open('Detailes.txt', 'w')\n",
    "# print('Starting iteration...')\n",
    "# while num_mel_bins <= 80:\n",
    "#     #print(num_mel_bins)\n",
    "#     total_time = 0\n",
    "#     for i in audio:\n",
    "#         tf_audio, rate = tf.audio.decode_wav(i)\n",
    "#         tf_audio = tf.squeeze(tf_audio, 1)\n",
    "#         start = time.time()\n",
    "#         STFT = tf.signal.stft(tf_audio, frame_length, frame_step,\n",
    "#                               fft_length=frame_length)\n",
    "#         spectrogram = tf.abs(STFT)\n",
    "#         num_spectrogram_bins = spectrogram.shape[-1]\n",
    "#         linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "#             num_mel_bins, num_spectrogram_bins, sampling_rate, lower_freq, upper_freq)\n",
    "#         mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
    "#         log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "#         mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "#         mfccs = mfccs[..., :coefficients]\n",
    "#         end = time.time()\n",
    "#         temp_time = end - start\n",
    "#         total_time = total_time + temp_time\n",
    "\n",
    "\n",
    "#     avg_time = total_time / len(audio)\n",
    "#     txt = 'Bin: ' + str(num_mel_bins) + '\\tavg time: ' + str(avg_time) + '\\n'\n",
    "#     tstFile.write(txt)\n",
    "#     num_mel_bins = num_mel_bins + 10\n",
    "#     print(txt)\n",
    "#     # print('Bin: ', num_mel_bins, '\\tavg time: ', avg_time)\n",
    "# tstFile.close()\n",
    "# print('Done Sire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above cell is available in the test_result.txt file\n",
    "<br>You can completely <b>ignore</b> the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average execution time of each iteration:  0.023845387935638427\n"
     ]
    }
   ],
   "source": [
    "# now we get the rate of our audio\n",
    "#these info are extracted from the homework pdf file\n",
    "total_time=0#to sum up the time of execution in each iteration\n",
    "frame_length=16\n",
    "frame_step=8\n",
    "num_mel_bins = 12\n",
    "sampling_rate = 16000\n",
    "lower_freq=20\n",
    "upper_freq=4000\n",
    "coefficients=10\n",
    "total_mfcc=0\n",
    "for i in audio:\n",
    "    tf_audio, rate = tf.audio.decode_wav(i)\n",
    "    tf_audio = tf.squeeze(tf_audio, 1)\n",
    "    start = time.time()\n",
    "    stft = tf.signal.stft(tf_audio, frame_length, frame_step,\n",
    "    fft_length=frame_length)\n",
    "    spectrogram = tf.abs(stft)\n",
    "    num_spectrogram_bins = spectrogram.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "        num_mel_bins, num_spectrogram_bins, sampling_rate, lower_freq, upper_freq)\n",
    "    mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "    mfccs = mfccs[..., :coefficients]\n",
    "    end = time.time()\n",
    "    total_mfcc=total_mfcc+mfccs\n",
    "    total_time=total_time+end-start\n",
    "    total_time=total_time+end-start\n",
    "    \n",
    "avg_time=total_time/len(audio)\n",
    "avg_mfcc_fast=total_mfcc/len(audio)\n",
    "\n",
    "print('average execution time of each iteration: ',avg_time)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SNR code is as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(MFCC_slow, MFCC_fast):\n",
    "    Numerator = LNG.norm(MFCC_slow)\n",
    "    Denominator = LNG.norm(MFCC_slow - MFCC_fast + 10 ** -6)\n",
    "    SNR_result = 20 * np.log(Numerator / Denominator)\n",
    "    return SNR_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.479350328445435"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we run the SNR function\n",
    "SNR(avg_mfcc_slow,avg_mfcc_fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to make a trade off between the execution time and SNR</br>\n",
    "in order to get the min exection time we had to set the number of bin equal to 1 </br>\n",
    "but that doesn't give us a good SNR so we had to change it and set it equla to 12 (after testing different values for the number of bins)</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final note\n",
    "<b>The code has been tested on Raspberry pi 4 and the .py files are uploaded. This file is for the sole purpose of having a btter understanding of the whole procedure. </b>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC slow =  5  ms\n",
      "tf.Tensor([124  10], shape=(2,), dtype=int32)\n",
      "MFCC fast =  3  ms\n",
      "tf.Tensor([124   5], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [124,10] vs. [124,5] [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11696/1518361342.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[0mmfcc_slow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'slow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mmfcc_fast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fast'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mSNR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc_slow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmfcc_slow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmfcc_fast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmfcc_fast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11696/1518361342.py\u001b[0m in \u001b[0;36mSNR\u001b[1;34m(mfcc_slow, mfcc_fast)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mSNR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc_slow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmfcc_fast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLNG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc_slow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdenominator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLNG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc_slow\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmfcc_fast\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0msnr_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumerator\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SNR = '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnr_result\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  10641\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10642\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10643\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10644\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10645\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [124,10] vs. [124,5] [Op:Sub]"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LNG\n",
    "\n",
    "Popen('sudo sh -c \"echo performance >'\n",
    "      '/sys/devices/system/cpu/cpufreq/policy0/scaling_governor\"',\n",
    "      shell=True).wait()\n",
    "\n",
    "\n",
    "def SNR(mfcc_slow, mfcc_fast):\n",
    "    numerator = LNG.norm(mfcc_slow)\n",
    "    denominator = LNG.norm(mfcc_slow - mfcc_fast + 10 ** -6)\n",
    "    snr_result = 20 * np.log(numerator / denominator)\n",
    "    print('SNR = ' + str(snr_result) + ' dB')\n",
    "\n",
    "\n",
    "def mfcc(bins, Audio, types):\n",
    "    tot_mfcc = 0\n",
    "    total_time = 0\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "        bins, 129 , sampling_rate, lower_freq, upper_freq)\n",
    "    for i in Audio:\n",
    "        tf_audio, rate = tf.audio.decode_wav(i)\n",
    "        tf_audio = tf.squeeze(tf_audio, 1)\n",
    "        start = time.time()\n",
    "        stft = tf.signal.stft(tf_audio, frame_length, frame_step,\n",
    "                              fft_length=frame_length)\n",
    "        spectrogram = tf.abs(stft)\n",
    "        num_spectrogram_bins = spectrogram.shape[-1]\n",
    "        #linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      # bin, num_spectrogram_bins, sampling_rate, lower_freq, upper_freq)\n",
    "        mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
    "        log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "        mfccs = mfccs[..., :coefficients]\n",
    "        end = time.time()\n",
    "        tot_mfcc = tot_mfcc + mfccs\n",
    "        temp_time = end - start\n",
    "        total_time = total_time + temp_time\n",
    "    avg_time = total_time / len(audio)\n",
    "    avg_mfcc = tot_mfcc / len(audio)\n",
    "    print('MFCC ' + types + ' = ', int(avg_time*1000), ' ms')\n",
    "    print(tf.shape(avg_mfcc))\n",
    "    return avg_mfcc\n",
    "\n",
    "\n",
    "frame_length = 256\n",
    "frame_step = 128\n",
    "\n",
    "sampling_rate = 16000\n",
    "lower_freq = 20\n",
    "upper_freq = 4000\n",
    "coefficients = 10\n",
    "\n",
    "DATASET_PATH = './yes_no'\n",
    "dir_list = os.listdir(DATASET_PATH)\n",
    "audio = []\n",
    "for i in dir_list:\n",
    "    audio.append(tf.io.read_file(DATASET_PATH+'/'+i))\n",
    "\n",
    "mfcc_slow = mfcc(bins=40, Audio=audio, types='slow')\n",
    "mfcc_fast = mfcc(bins=5, Audio=audio, types='fast')\n",
    "SNR(mfcc_slow=mfcc_slow, mfcc_fast=mfcc_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input INPUT] [--output OUTPUT] [--normalize]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\aligh\\AppData\\Roaming\\jupyter\\runtime\\kernel-09e27e38-f7e6-4b2b-baa0-64c25960fa35.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aligh\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "# import adafruit_dht\n",
    "import os\n",
    "\n",
    "\n",
    "def norm(t, t_min, t_max):\n",
    "    return (t - t_min) / (t_max - t_min)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input', type=str, help='specify the csv input file')\n",
    "parser.add_argument('--output', type=str, help='specify output file name with tfrecord extension')\n",
    "parser.add_argument('--normalize', action=\"store_true\", help='for normalizing the humidity and temperature')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Code to get humidity & Tempreture from sendor and save in a CSV file\n",
    "# period = 60\n",
    "# freq = 5\n",
    "# num_samples = int(period // freq)\n",
    "# dht_device = adafruit_dht.DHT11(D4)\n",
    "# for i in range(num_samples):\n",
    "#     now = datetime.datetime.now()\n",
    "#     temperature = dht_device.temperature\n",
    "#     humidity = dht_device.humidity\n",
    "#     print('{:02}/{:02}/{:04},{:02}:{:02}:{:02},{:},{:}'.format(now.day, now.month, now.year, now.hour, now.minute,\n",
    "#                                                                now.second, temperature, humidity), file=fp)\n",
    "#     time.sleep(args.f)\n",
    "# file = pd.read_csv('rt.txt', header=None)\n",
    "# file.columns = ['date', 'time', 'temperature', 'humidity']\n",
    "# file.to_csv('rt.csv', index=None)\n",
    "\n",
    "cols = ['date', 'time']\n",
    "conv = pd.read_csv(args.input, usecols=cols).values  # reading the csv file\n",
    "\n",
    "# code to convert the date and time to POSIX fornmat\n",
    "timestamp = []\n",
    "for i in conv:\n",
    "    temp = i[0] + ' ' + i[1]\n",
    "    element = datetime.datetime.strptime(temp, \"%d/%m/%Y %H:%M:%S\")\n",
    "    tmp_tuple = element.timetuple()\n",
    "    timestamp.append(time.mktime(tmp_tuple))\n",
    "new_csv = pd.read_csv(\"rt.csv\")\n",
    "new_csv = new_csv.drop(['date', 'time'], axis=1)\n",
    "new_csv.insert(0, \"datetime\", timestamp)\n",
    "new_csv = new_csv.astype({'temperature': int})\n",
    "new_csv = new_csv.values\n",
    "\n",
    "if args.normalize:\n",
    "    temperature = new_csv.loc[:, 'temperature']\n",
    "    humidity = new_csv.loc[:, 'humidity']\n",
    "    norm_temperature = []\n",
    "    norm_humidity = []\n",
    "    for i in temperature:\n",
    "        norm_temperature.append(norm(i, 0, 50))\n",
    "    for i in humidity:\n",
    "        norm_humidity.append(norm(i, 20, 90))\n",
    "    Data = {'datetime': new_csv.loc[:, 'datetime'], 'temperature': norm_temperature, 'humidity': norm_humidity}\n",
    "    norm_csv = pd.DataFrame(data=Data)\n",
    "\n",
    "with tf.io.TFRecordWriter(args.output) as writer:\n",
    "    for row in new_csv:\n",
    "        # features, label = row[:-1], row[-1]\n",
    "        features = row\n",
    "        example = tf.train.Example()\n",
    "        example.features.feature[\"features\"].float_list.value.extend(features)\n",
    "        # example.features.feature[\"label\"].float_list.value.append(label)\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "print(os.path.getsize(args.output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
