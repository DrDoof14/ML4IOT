{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e62bcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9200/9200 [==============================] - 27s 3ms/step - loss: 0.1132\n",
      "Epoch 2/20\n",
      "9200/9200 [==============================] - 25s 3ms/step - loss: 0.0959\n",
      "Epoch 3/20\n",
      "9200/9200 [==============================] - 25s 3ms/step - loss: 0.0941\n",
      "Epoch 4/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0934\n",
      "Epoch 5/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0928\n",
      "Epoch 6/20\n",
      "9200/9200 [==============================] - 25s 3ms/step - loss: 0.0924\n",
      "Epoch 7/20\n",
      "9200/9200 [==============================] - 27s 3ms/step - loss: 0.0922\n",
      "Epoch 8/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0920\n",
      "Epoch 9/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0919\n",
      "Epoch 10/20\n",
      "9200/9200 [==============================] - 25s 3ms/step - loss: 0.0918\n",
      "Epoch 11/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0918\n",
      "Epoch 12/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0917\n",
      "Epoch 13/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0917\n",
      "Epoch 14/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0916\n",
      "Epoch 15/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0916\n",
      "Epoch 16/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0915\n",
      "Epoch 17/20\n",
      "9200/9200 [==============================] - 27s 3ms/step - loss: 0.0915\n",
      "Epoch 18/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0914\n",
      "Epoch 19/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0914\n",
      "Epoch 20/20\n",
      "9200/9200 [==============================] - 26s 3ms/step - loss: 0.0913\n",
      "1314/1314 - 1s\n",
      "Test Temperature MAE(Before Pruning): 0.059239395\n",
      "Test Humidity MAE(Before Pruning): 0.12889965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aligh\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:2223: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   6/9200 [..............................] - ETA: 10:10 - loss: 0.1069 - mae: 0.1069WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.0485s). Check your callbacks.\n",
      "9200/9200 [==============================] - 54s 6ms/step - loss: 0.0912 - mae: 0.0912\n",
      "Epoch 2/20\n",
      "9200/9200 [==============================] - 53s 6ms/step - loss: 0.0911 - mae: 0.0911\n",
      "Epoch 3/20\n",
      "9200/9200 [==============================] - 51s 6ms/step - loss: 0.0912 - mae: 0.0912\n",
      "Epoch 4/20\n",
      "9200/9200 [==============================] - 53s 6ms/step - loss: 0.0914 - mae: 0.0914\n",
      "Epoch 5/20\n",
      "9200/9200 [==============================] - 53s 6ms/step - loss: 0.0916 - mae: 0.0916\n",
      "Epoch 6/20\n",
      "9200/9200 [==============================] - 52s 6ms/step - loss: 0.0935 - mae: 0.0935\n",
      "Epoch 7/20\n",
      "9200/9200 [==============================] - 54s 6ms/step - loss: 0.0937 - mae: 0.0937\n",
      "Epoch 8/20\n",
      "9200/9200 [==============================] - 51s 6ms/step - loss: 0.0946 - mae: 0.0946\n",
      "Epoch 9/20\n",
      "9200/9200 [==============================] - 47s 5ms/step - loss: 0.0951 - mae: 0.0951\n",
      "Epoch 10/20\n",
      "9200/9200 [==============================] - 51s 6ms/step - loss: 0.0936 - mae: 0.0936\n",
      "Epoch 11/20\n",
      "9200/9200 [==============================] - 49s 5ms/step - loss: 0.0940 - mae: 0.0940\n",
      "Epoch 12/20\n",
      "9200/9200 [==============================] - 49s 5ms/step - loss: 0.0941 - mae: 0.0941\n",
      "Epoch 13/20\n",
      "9200/9200 [==============================] - 50s 5ms/step - loss: 0.0958 - mae: 0.0958\n",
      "Epoch 14/20\n",
      "9200/9200 [==============================] - 52s 6ms/step - loss: 0.0949 - mae: 0.0949\n",
      "Epoch 15/20\n",
      "9200/9200 [==============================] - 53s 6ms/step - loss: 0.0947 - mae: 0.0947\n",
      "Epoch 16/20\n",
      "9200/9200 [==============================] - 53s 6ms/step - loss: 0.0947 - mae: 0.0947\n",
      "Epoch 17/20\n",
      "9200/9200 [==============================] - 55s 6ms/step - loss: 0.0946 - mae: 0.0946\n",
      "Epoch 18/20\n",
      "9200/9200 [==============================] - 51s 6ms/step - loss: 0.0946 - mae: 0.0946\n",
      "Epoch 19/20\n",
      "9200/9200 [==============================] - 51s 6ms/step - loss: 0.0946 - mae: 0.0946\n",
      "Epoch 20/20\n",
      "9200/9200 [==============================] - 50s 5ms/step - loss: 0.0945 - mae: 0.0945\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\aligh\\AppData\\Local\\Temp\\tmpa6grth5r\\assets\n",
      "Compressed size: 1356\n",
      "1314/1314 - 1s\n",
      "Test Temperature MAE(After Pruning): 0.06315785\n",
      "Test Humidity MAE(After Pruning): 0.13237269\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import argparse\n",
    "from keras.metrics import mean_absolute_error as mae\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--version', type=str, required=True,\n",
    "#                     help='choosing the output step')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# output_steps = 3\n",
    "output_steps = 9\n",
    "\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True,\n",
    "    cache_dir='.', cache_subdir='data')\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "column_indices = [2, 5]\n",
    "columns = df.columns[column_indices]\n",
    "data = df[columns].values.astype(np.float32)\n",
    "\n",
    "n = len(data)\n",
    "train_data = data[0:int(n * 0.7)]\n",
    "test_data = data[int(n * 0.9):]\n",
    "\n",
    "\n",
    "def window_gen(data, input_length, output_length, vectorize):\n",
    "    x = []\n",
    "    y = []\n",
    "    for index in range(0, len(data) - input_length - output_length):\n",
    "        x.append(data[index:index + input_length])\n",
    "        output_loc = data[index + input_length:index + input_length + output_length]\n",
    "        if vectorize == True:\n",
    "            y.append(output_loc.reshape(-1))\n",
    "        else:\n",
    "            y.append(output_loc)\n",
    "    x = np.array(x)  # to make it possible to run\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def mlp_model(out_steps, alpha=1):\n",
    "    mlp = keras.Sequential()\n",
    "    mlp.add(keras.Input(shape=(input_steps, 2)))\n",
    "    mlp.add(layers.Flatten())\n",
    "    mlp.add(layers.Dense(units=128 * alpha, activation='relu'))\n",
    "    mlp.add(layers.Dense(units=128 * alpha, activation='relu'))\n",
    "    mlp.add(layers.Dense(units=out_steps * 2))\n",
    "    mlp.compile(loss='mae', optimizer='adam')\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def cnn_model(out_steps, alpha=1):\n",
    "    cnn = tf.keras.Sequential([\n",
    "        layers.Conv1D(filters=64 * alpha, kernel_size=(3,), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "#         layers.Dense(units=64 * alpha, activation='relu'),\n",
    "        layers.Dense(units=out_steps * 2)\n",
    "    ])\n",
    "    cnn.compile(loss='mae', optimizer='adam')\n",
    "    return cnn\n",
    "\n",
    "\n",
    "def normalization(x, y):\n",
    "    x_mean = np.mean(x, axis=0)\n",
    "    y_mean = np.mean(y, axis=0)\n",
    "    x_std = np.std(x, axis=0)\n",
    "    y_std = np.std(y, axis=0)\n",
    "    x_norm = (x - x_mean) / (x_std + 1.e-6)\n",
    "    y_norm = (y - y_mean) / (y_std + 1.e-6)\n",
    "\n",
    "    return x_norm, y_norm\n",
    "\n",
    "\n",
    "input_steps = 6\n",
    "\n",
    "x_train, y_train = window_gen(train_data, input_steps, output_steps, True)\n",
    "x_test, y_test = window_gen(test_data, input_steps, output_steps, True)\n",
    "\n",
    "x_train_norm, y_train_norm = normalization(x_train, y_train)\n",
    "x_test_norm, y_test_norm = normalization(x_test, y_test)\n",
    "\n",
    "model = cnn_model(out_steps=output_steps, alpha=0.25)\n",
    "model.fit(x_train_norm, y_train_norm, batch_size=32, epochs=20)\n",
    "y_test_predict = model.predict(x_test_norm, verbose=2)\n",
    "\n",
    "y_test_temperature = y_test_norm[:, 0::2]\n",
    "y_test_humidity = y_test_norm[:, 1::2]\n",
    "y_test_temperature_predicted = y_test_predict[:, 0::2]\n",
    "y_test_humidity_predicted = y_test_predict[:, 1::2]\n",
    "\n",
    "test_temperature_mae = mae(y_test_temperature, y_test_temperature_predicted).numpy()\n",
    "print(\"Test Temperature MAE(Before Pruning):\", np.mean(test_temperature_mae))\n",
    "test_humidity_mae = mae(y_test_humidity, y_test_humidity_predicted).numpy()\n",
    "print(\"Test Humidity MAE(Before Pruning):\", np.mean(test_humidity_mae))\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "\n",
    "num_train = 294370 * (1 - validation_split)\n",
    "end_step = np.ceil(num_train / batch_size).astype(np.int32) * epochs\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
    "                                                             final_sparsity=0.9,\n",
    "                                                             begin_step=0,\n",
    "                                                             end_step=end_step)\n",
    "}\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "                          loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                          metrics=['mae'])\n",
    "logdir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(x_train_norm, y_train_norm,\n",
    "                      batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_tflite_model = converter.convert()\n",
    "pruned_tflite_file = './pruned_model' + str(output_steps) + '.tflite'\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "\n",
    "import zlib, sys\n",
    "\n",
    "filename_in = pruned_tflite_file\n",
    "filename_out = \"./compressed_model\" + str(output_steps) + \".tflite.zlib\"\n",
    "\n",
    "with open(filename_in, mode=\"rb\") as fin, open(filename_out, mode=\"wb\") as fout:\n",
    "    data = fin.read()\n",
    "    compressed_data = zlib.compress(data, 9)\n",
    "    print(f\"Compressed size: {sys.getsizeof(compressed_data)}\")\n",
    "    fout.write(compressed_data)\n",
    "\n",
    "# **********MAE for the pruned model************\n",
    "y_test_predict_prune = model_for_pruning.predict(x_test_norm, verbose=2)\n",
    "y_test_temperature_predicted_pruned = y_test_predict_prune[:, 0::2]\n",
    "y_test_humidity_predicted_pruned = y_test_predict_prune[:, 1::2]\n",
    "test_temperature_mae_pruned = tf.keras.metrics.mean_absolute_error(y_test_temperature,\n",
    "                                                                   y_test_temperature_predicted_pruned)\n",
    "print(\"Test Temperature MAE(After Pruning):\", np.mean(test_temperature_mae_pruned))\n",
    "\n",
    "test_humidity_mae_pruned = tf.keras.metrics.mean_absolute_error(y_test_humidity, y_test_humidity_predicted_pruned)\n",
    "print(\"Test Humidity MAE(After Pruning):\", np.mean(test_humidity_mae_pruned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10d1e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c945f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
